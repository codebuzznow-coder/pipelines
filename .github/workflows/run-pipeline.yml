# GitHub Actions workflow to run data pipeline
# This can be triggered manually or when data files are uploaded

name: Run Data Pipeline

on:
  workflow_dispatch:
    inputs:
      s3_path:
        description: 'S3 URI only (e.g. s3://survey-qa-data-301625833185/survey_data/) — NOT the console URL'
        required: true
        default: ''
      sample_pct:
        description: 'Sample percentage (1-100)'
        required: false
        default: '5'
      seed:
        description: 'Random seed'
        required: false
        default: '42'

env:
  AWS_REGION: us-east-1

jobs:
  run-pipeline:
    name: Run Data Pipeline on EC2
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Validate S3 path
        run: |
          S3_PATH="${{ github.event.inputs.s3_path }}"
          if [[ ! "$S3_PATH" =~ ^s3:// ]]; then
            echo "::error::S3_PATH must be an S3 URI, e.g. s3://survey-qa-data-301625833185/survey_data/"
            echo "You entered something like a console URL. Use the bucket name and prefix only."
            exit 1
          fi
          echo "Using S3 path: $S3_PATH"
      
      - name: Run Data Pipeline (SSH)
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
          S3_PATH: ${{ github.event.inputs.s3_path }}
          SAMPLE_PCT: ${{ github.event.inputs.sample_pct }}
          SEED: ${{ github.event.inputs.seed }}
          REGION: ${{ env.AWS_REGION }}
        run: |
          set -e
          if [ -z "$EC2_HOST" ] || [ -z "$EC2_SSH_KEY" ]; then
            echo "::error::Set EC2_HOST and EC2_SSH_KEY in repo secrets (Settings -> Secrets -> Actions). Security group must allow SSH (port 22) from 0.0.0.0/0."
            exit 1
          fi
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          REMOTE_CMD="TEMP_DIR=\$(mktemp -d); aws s3 sync '$S3_PATH' \$TEMP_DIR/ --region '$REGION' --exclude '*' --include '*.csv' --include '*.zip'; sudo docker exec survey-qa python -m data_pipeline.run_pipeline --input \$TEMP_DIR --sample-pct $SAMPLE_PCT --seed $SEED; rm -rf \$TEMP_DIR"
          ssh -o StrictHostKeyChecking=no -o ConnectTimeout=30 -i ~/.ssh/deploy_key ec2-user@$EC2_HOST "$REMOTE_CMD"
          echo "✅ Pipeline completed. App: http://$EC2_HOST:8501"
