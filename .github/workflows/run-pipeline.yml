# GitHub Actions workflow to run data pipeline
# This can be triggered manually or when data files are uploaded

name: Run Data Pipeline

on:
  workflow_dispatch:
    inputs:
      s3_path:
        description: 'S3 URI only (e.g. s3://survey-qa-data-301625833185/survey_data/) — NOT the console URL'
        required: true
        default: ''
      sample_pct:
        description: 'Sample percentage (1-100)'
        required: false
        default: '5'
      seed:
        description: 'Random seed'
        required: false
        default: '42'

env:
  AWS_REGION: us-east-1

jobs:
  run-pipeline:
    name: Run Data Pipeline on EC2
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Validate S3 path
        run: |
          S3_PATH="${{ github.event.inputs.s3_path }}"
          if [[ ! "$S3_PATH" =~ ^s3:// ]]; then
            echo "::error::S3_PATH must be an S3 URI, e.g. s3://survey-qa-data-301625833185/survey_data/"
            echo "You entered something like a console URL. Use the bucket name and prefix only."
            exit 1
          fi
          echo "Using S3 path: $S3_PATH"
      
      - name: Run Data Pipeline (SSH)
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
          S3_PATH: ${{ github.event.inputs.s3_path }}
          SAMPLE_PCT: ${{ github.event.inputs.sample_pct }}
          SEED: ${{ github.event.inputs.seed }}
          REGION: ${{ env.AWS_REGION }}
        run: |
          set -e
          if [ -z "$EC2_HOST" ] || [ -z "$EC2_SSH_KEY" ]; then
            echo "::error::Set EC2_HOST and EC2_SSH_KEY in repo secrets (Settings -> Secrets -> Actions). Security group must allow SSH (port 22) from 0.0.0.0/0."
            exit 1
          fi
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          # -T: no pseudo-terminal (avoids "Pseudo-terminal will not be allocated" in CI)
          # -o ServerAliveInterval/CountMax: detect dead connections; ConnectionTimeout for initial connect
          SSH_OPTS="-T -o StrictHostKeyChecking=no -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=3 -i ~/.ssh/deploy_key"
          REMOTE_CMD="set -e; TEMP_DIR=\$(mktemp -d); CONTAINER_INPUT=/tmp/pipeline_input; echo 'Listing S3 path...'; if ! aws s3 ls '$S3_PATH' --region '$REGION' 2>&1; then echo '::warning::aws s3 ls failed (check EC2 IAM role has s3:ListBucket on the bucket).'; fi; echo 'Syncing...'; aws s3 sync '$S3_PATH' \$TEMP_DIR/ --region '$REGION' --exclude '*' --include '*.csv' --include '*.zip' 2>&1 || true; echo 'Contents of temp dir (on host):'; ls -la \$TEMP_DIR; CSV_CNT=\$(find \$TEMP_DIR -name '*.csv' 2>/dev/null | wc -l); ZIP_CNT=\$(find \$TEMP_DIR -name '*.zip' 2>/dev/null | wc -l); if [ \$CSV_CNT -eq 0 ] && [ \$ZIP_CNT -eq 0 ]; then echo '::error::No CSV or ZIP at $S3_PATH. Fix: 1) Add ec2_additional_s3_bucket_arns in infra/terraform.tfvars and run terraform apply. 2) Ensure EC2 instance has IAM role. 3) Upload CSV or ZIP under the prefix (e.g. survey_data/).'; rm -rf \$TEMP_DIR; exit 1; fi; echo 'Copying data into container...'; sudo docker exec survey-qa rm -rf \$CONTAINER_INPUT; sudo docker exec survey-qa mkdir -p \$CONTAINER_INPUT; sudo docker cp \$TEMP_DIR/. survey-qa:\$CONTAINER_INPUT/; sudo docker exec -e PYTHONUNBUFFERED=1 survey-qa python -m data_pipeline.run_pipeline --input \$CONTAINER_INPUT --sample-pct $SAMPLE_PCT --seed $SEED; sudo docker exec survey-qa rm -rf \$CONTAINER_INPUT; rm -rf \$TEMP_DIR"
          # Retry SSH up to 3 times (connection reset by peer / kex_exchange_identification can be transient)
          for attempt in 1 2 3; do
            if ssh $SSH_OPTS ec2-user@$EC2_HOST "$REMOTE_CMD"; then
              echo "✅ Pipeline completed. App: http://$EC2_HOST:8501"
              exit 0
            fi
            echo "SSH attempt $attempt failed (exit $?). Retrying in 15s..."
            sleep 15
          done
          echo "::error::SSH to EC2 failed after 3 attempts. Check: EC2 running, security group allows port 22 from 0.0.0.0/0, correct EC2_HOST and EC2_SSH_KEY."
          exit 255
