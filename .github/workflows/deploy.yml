# GitHub Actions workflow for CI/CD
# Save as: .github/workflows/deploy.yml

name: Build and Deploy

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: survey-qa
  IMAGE_TAG: ${{ github.sha }}

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r app/requirements.txt
          pip install pytest
      
      - name: Run tests
        run: |
          cd data_pipeline
          python -m pytest tests/ -v

  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG -f deploy/Dockerfile .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

  deploy:
    name: Deploy to EC2
    runs-on: ubuntu-latest
    needs: build
    if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Deploy to EC2
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
          ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com
          ECR_REPO: ${{ env.ECR_REPOSITORY }}
          REGION: ${{ env.AWS_REGION }}
        run: |
          set -e
          if [ -z "$EC2_HOST" ] || [ -z "$EC2_SSH_KEY" ]; then
            echo "::error::EC2_HOST and EC2_SSH_KEY must be set in repo secrets."
            exit 1
          fi
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          SSH_OPTS="-T -o StrictHostKeyChecking=no -o ConnectTimeout=45 -o ServerAliveInterval=15 -o ServerAliveCountMax=3 -i ~/.ssh/deploy_key"
          for attempt in 1 2 3; do
            echo "Deploy attempt $attempt/3..."
            if ssh $SSH_OPTS ec2-user@$EC2_HOST bash -s << ENDSSH
              set -e
              ECR_REGISTRY="${ECR_REGISTRY}"
              ECR_REPO="${ECR_REPO}"
              REGION="${REGION}"
              aws ecr get-login-password --region \$REGION | sudo docker login --username AWS --password-stdin \$ECR_REGISTRY
              sudo docker pull \$ECR_REGISTRY/\$ECR_REPO:latest
              sudo docker stop survey-qa || true
              sudo docker rm survey-qa || true
              sudo docker run -d --name survey-qa --restart unless-stopped -p 8501:8501 -v survey-data:/app/data \$ECR_REGISTRY/\$ECR_REPO:latest
              sleep 10
              curl -f http://localhost:8501/_stcore/health || exit 1
          ENDSSH
            then
              echo "Deploy succeeded."
              exit 0
            fi
            [ $attempt -lt 3 ] && echo "SSH failed. Retrying in 20s..." && sleep 20
          done
          echo "::error::SSH to EC2 failed after 3 attempts. Connection timed out = port 22 not reachable from GitHub. Fix: 1) Security group: allow inbound port 22 from 0.0.0.0/0. 2) EC2 running with public IP. 3) EC2_HOST = that public IP. See README Troubleshooting."
          exit 255
      
      - name: Run Data Pipeline (Optional)
        if: success()
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          REGION: ${{ env.AWS_REGION }}
        run: |
          if [ -z "$S3_BUCKET" ] || [ -z "$EC2_HOST" ] || [ -z "$EC2_SSH_KEY" ]; then
            echo "S3_BUCKET, EC2_HOST, or EC2_SSH_KEY not set. Skipping optional pipeline. Use the 'Run Data Pipeline' workflow to run with your S3 path."
            exit 0
          fi
          mkdir -p ~/.ssh
          echo "$EC2_SSH_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh -T -o StrictHostKeyChecking=no -o ConnectTimeout=30 -o ServerAliveInterval=15 -o ServerAliveCountMax=3 -i ~/.ssh/deploy_key ec2-user@$EC2_HOST << ENDSSH
            # Check if data exists in S3
            if aws s3 ls s3://${S3_BUCKET}/survey_data/ --region ${REGION} 2>/dev/null | grep -qE "\.(csv|zip)"; then
              echo "Found CSV or ZIP files in S3, running data pipeline..."
              
              # Create data directory
              mkdir -p /tmp/survey_data
              
              # Download CSV and ZIP files from S3 (pipeline extracts zips automatically)
              aws s3 sync s3://${S3_BUCKET}/survey_data/ /tmp/survey_data/ --region ${REGION} --exclude "*" --include "*.csv" --include "*.zip"
              
              # Run pipeline inside the container
              sudo docker exec survey-qa python -m data_pipeline.run_pipeline \
                --input /tmp/survey_data \
                --sample-pct 5 \
                --seed 42 || echo "Pipeline run completed (check logs if errors)"
              
              echo "Data pipeline completed!"
            else
              echo "No CSV files found in S3. Skipping pipeline run."
              echo "You can upload data via the web UI at http://\$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4):8501"
            fi
          ENDSSH
      
      - name: Notify deployment
        if: success()
        run: |
          echo "Deployment successful!"
          echo "App URL: http://${{ secrets.EC2_HOST }}:8501"
          echo ""
          echo "To run the data pipeline:"
          echo "1. Upload CSV files via the web UI (Data Pipeline section)"
          echo "2. Upload files to S3 and use the 'Run Data Pipeline' workflow"
          echo "3. Or SSH to EC2 and run manually"
